{"input": ["insensitiveCase/corpus.tc.32k.tr.shuf", "insensitiveCase/corpus.tc.32k.en.shuf"], "output": "train", "model": "deeplstm", "vocab": ["insensitiveCase/vocab.32k.tr.txt", "insensitiveCase/vocab.32k.en.txt"], "pad": "<pad>", "bos": "<eos>", "eos": "<eos>", "unk": "<unk>", "batch_size": 512, "fixed_batch_size": false, "min_length": 1, "max_length": 256, "buffer_size": 10000, "initializer_gain": 1.0, "initializer": "uniform_unit_scaling", "scale_l1": 0.0, "scale_l2": 0.0, "initial_step": 0, "warmup_steps": 4000, "train_steps": 100000, "update_cycle": 2, "optimizer": "Adam", "adam_beta1": 0.9, "adam_beta2": 0.98, "adam_epsilon": 1e-09, "adadelta_rho": 0.95, "adadelta_epsilon": 1e-07, "pattern": "", "clipping": "global_norm", "clip_grad_norm": 0.0, "learning_rate": 0.0007, "initial_learning_rate": 0.0, "learning_rate_schedule": "linear_warmup_rsqrt_decay", "learning_rate_boundaries": [0], "learning_rate_values": [0.0], "device_list": [0], "keep_checkpoint_max": 20, "keep_top_checkpoint_max": 5, "save_summary": true, "save_checkpoint_secs": 0, "save_checkpoint_steps": 1000, "eval_steps": 2000, "eval_secs": 0, "top_beams": 1, "beam_size": 4, "decode_batch_size": 32, "decode_alpha": 0.6, "decode_ratio": 1.0, "decode_length": 50, "validation": "insensitiveCase/dev.tc.32k.tr", "references": "insensitiveCase/dev.tc.en", "hidden_size": 512, "filter_size": 2048, "num_heads": 8, "num_encoder_layers": 6, "num_decoder_layers": 4, "attention_dropout": 0.0, "residual_dropout": 0.1, "relu_dropout": 0.0, "label_smoothing": 0.1, "lstm_normalization": false, "lstm_activation": null, "comb_mode": "sum", "lstm_num_heads": 1}